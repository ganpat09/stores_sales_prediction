{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "#os.chdir(\"./stores_sales_prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " 'artifacts',\n",
       " 'configs',\n",
       " 'dvc.yaml',\n",
       " 'env',\n",
       " 'init_setup.sh',\n",
       " 'LICENSE',\n",
       " 'logs',\n",
       " 'params.yaml',\n",
       " 'pyproject.toml',\n",
       " 'README.md',\n",
       " 'requirements.txt',\n",
       " 'requirements_dev.txt',\n",
       " 'research',\n",
       " 'setup.cfg',\n",
       " 'setup.py',\n",
       " 'src',\n",
       " 'template.py',\n",
       " 'tests',\n",
       " 'tox.ini']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import index\n",
    "from saleStorePredictor.utils import read_yaml,save_numpy_array_data,load_bin,save_bin,create_directories\n",
    "import os\n",
    "from saleStorePredictor.entity import DataTransformationConfig\n",
    "from saleStorePredictor.config import ConfigurationManager\n",
    "from saleStorePredictor import logging\n",
    "from sklearn import preprocessing\n",
    "import sys,os\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FeatureGenerator(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self, columns=None):\n",
    "        \"\"\"\n",
    "        FeatureGenerator Initialization\n",
    "        \n",
    "        \"\"\"\n",
    "        self.columns = columns\n",
    "        \n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        try:\n",
    "            X[\"Item_type_combined\"] = X['Item_Identifier'].apply(lambda x:x[0:2])\n",
    "\n",
    "            return X\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error generating feature {e}.\") \n",
    "\n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = pd.DataFrame(X,columns=self.columns)\n",
    "        logging.info(output.columns)\n",
    "        if self.columns is not None:\n",
    "            for id,col in enumerate(self.columns):\n",
    "                \n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)            \n",
    "\n",
    "\n",
    "\n",
    "class DataTransformation:\n",
    "\n",
    "    def __init__(self,data_transformation_config:DataTransformationConfig):\n",
    "        self.data_transformation_config = data_transformation_config\n",
    "        self.train = pd.read_csv(self.data_transformation_config.training_dataset,index_col=False)\n",
    "        self.test = pd.read_csv(self.data_transformation_config.test_dataset,index_col=False)\n",
    "\n",
    "\n",
    "    def get_data_transformer_object(self)->ColumnTransformer:\n",
    "        try:\n",
    "            schema_file_path = Path(self.data_transformation_config.schema_path)\n",
    "\n",
    "            dataset_schema = read_yaml(schema_file_path)\n",
    "\n",
    "            numerical_columns = dataset_schema.numerical_columns\n",
    "            categorical_columns = dataset_schema.categorical_columns\n",
    "\n",
    "\n",
    "            num_pipeline = Pipeline(steps=[\n",
    "                ('imputer', SimpleImputer(strategy=\"mean\")),\n",
    "               # ('scaler', StandardScaler())\n",
    "            ]\n",
    "            )\n",
    "\n",
    "            cat_pipeline = Pipeline(steps=[\n",
    "               ('feature_generator', FeatureGenerator(columns=categorical_columns)),\n",
    "                 ('impute', SimpleImputer(strategy=\"most_frequent\")),\n",
    "               \n",
    "\n",
    "            ]\n",
    "            )\n",
    "\n",
    "\n",
    "            encoding_scaling = Pipeline(steps=[\n",
    "                  ('encoding',MultiColumnLabelEncoder(columns=categorical_columns)),\n",
    "                 ('scaler', StandardScaler(with_mean=False))\n",
    "\n",
    "            ]\n",
    "            )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            logging.info(f\"Categorical columns preprocess: {categorical_columns}\")\n",
    "            logging.info(f\"Numerical columns preprocess: {numerical_columns}\")\n",
    "\n",
    "            extra_columns = ['Item_type_combined']\n",
    "\n",
    "\n",
    "            preprocessing = ColumnTransformer([\n",
    "                ('num_pipeline', num_pipeline, numerical_columns),\n",
    "                ('cat_pipeline', cat_pipeline, categorical_columns),\n",
    "                ('encoding_scaling', encoding_scaling, numerical_columns + categorical_columns )\n",
    "            ])\n",
    "            return preprocessing\n",
    "\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            logging.error(f\"Error in preprocessing: {e}\") \n",
    "\n",
    "\n",
    "    def initiate_data_transformation(self):\n",
    "        try:\n",
    "            logging.info(f\"Obtaining preprocessing object.\")\n",
    "            preprocessing_obj = self.get_data_transformer_object()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            logging.info(f\"Obtaining training and test file path.\")\n",
    "            train_file_path = Path(self.data_transformation_config.training_dataset)\n",
    "            test_file_path =  Path(self.data_transformation_config.test_dataset)\n",
    "            \n",
    "\n",
    "            schema_file_path = Path(self.data_transformation_config.schema_path)\n",
    "            \n",
    "            logging.info(f\"Loading training and test data as pandas dataframe.\")\n",
    "            train_df = pd.read_csv(train_file_path)\n",
    "            \n",
    "            test_df = pd.read_csv(test_file_path)    \n",
    "\n",
    "            schema = read_yaml(schema_file_path)\n",
    "\n",
    "            target_column_name = schema.target_column\n",
    "\n",
    "\n",
    "            logging.info(f\"Splitting input and target feature from training and testing dataframe.\")\n",
    "            input_feature_train_df = train_df.drop(columns=[target_column_name],axis=1)\n",
    "            target_feature_train_df = train_df[target_column_name]\n",
    "\n",
    "            input_feature_test_df = test_df.drop(columns=[target_column_name],axis=1)\n",
    "            target_feature_test_df = test_df[target_column_name]\n",
    "            \n",
    "\n",
    "            logging.info(f\"Applying preprocessing object on training dataframe and testing dataframe\")\n",
    "            input_feature_train_arr= preprocessing_obj.fit_transform(input_feature_train_df)\n",
    "            input_feature_test_arr = preprocessing_obj.transform(input_feature_test_df)\n",
    "\n",
    "\n",
    "            train_arr = np.c_[ input_feature_train_arr, np.array(target_feature_train_df)]\n",
    "\n",
    "            test_arr = np.c_[input_feature_test_arr, np.array(target_feature_test_df)]\n",
    "            \n",
    "            transformed_train_dir = Path(self.data_transformation_config.transformed_train_path_file)\n",
    "            transformed_test_dir = Path(self.data_transformation_config.transformed_test_path_file)\n",
    "\n",
    "            train_file_name = os.path.basename(train_file_path).replace(\".csv\",\".npz\")\n",
    "            test_file_name = os.path.basename(test_file_path).replace(\".csv\",\".npz\")\n",
    "\n",
    "            transformed_train_file_path = os.path.join(transformed_train_dir, train_file_name)\n",
    "            transformed_test_file_path = os.path.join(transformed_test_dir, test_file_name)\n",
    "\n",
    "            logging.info(f\"Saving transformed training and testing array.\")\n",
    "            \n",
    "            save_numpy_array_data(file_path=transformed_train_file_path,array=train_arr)\n",
    "            save_numpy_array_data(file_path=transformed_test_file_path,array=test_arr)\n",
    "\n",
    "            \n",
    "\n",
    "            preprocessing_obj_file_path = Path(self.data_transformation_config.preprocessed_object_path_file)\n",
    "\n",
    "            create_directories([os.path.dirname(preprocessing_obj_file_path)])\n",
    "\n",
    "            logging.info(f\"Saving preprocessing object at {preprocessing_obj_file_path} type {type(preprocessing_obj)}\")\n",
    "            save_bin(preprocessing_obj,preprocessing_obj_file_path)\n",
    "\n",
    "            \n",
    "            \n",
    "            logging.info(f\"Data transformationa completed successfully.\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise e\n",
    "            logging.error(f\"Error Saving preprocessing object: {e.with_traceback}\")\n",
    "\n",
    "    def __del__(self):\n",
    "        logging.info(f\"{'>>'*30}Data Transformation log completed.{'<<'*30} \\n\\n\")    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-09-24 16:54:33,218: INFO: common]: yaml file: configs\\config.yaml loaded successfully\n",
      "[2022-09-24 16:54:33,220: INFO: common]: yaml file: params.yaml loaded successfully\n",
      "[2022-09-24 16:54:33,221: INFO: common]: created directory at: artifacts\n",
      "[2022-09-24 16:54:33,245: INFO: 2476690654]: Obtaining preprocessing object.\n",
      "[2022-09-24 16:54:33,252: INFO: common]: yaml file: configs\\schema.yaml loaded successfully\n",
      "[2022-09-24 16:54:33,253: INFO: 2476690654]: Categorical columns preprocess: ['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type']\n",
      "[2022-09-24 16:54:33,254: INFO: 2476690654]: Numerical columns preprocess: ['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year']\n",
      "[2022-09-24 16:54:33,255: INFO: 2476690654]: Obtaining training and test file path.\n",
      "[2022-09-24 16:54:33,256: INFO: 2476690654]: Loading training and test data as pandas dataframe.\n",
      "[2022-09-24 16:54:33,280: INFO: common]: yaml file: configs\\schema.yaml loaded successfully\n",
      "[2022-09-24 16:54:33,281: INFO: 2476690654]: Splitting input and target feature from training and testing dataframe.\n",
      "[2022-09-24 16:54:33,284: INFO: 2476690654]: Applying preprocessing object on training dataframe and testing dataframe\n",
      "[2022-09-24 16:54:33,298: INFO: 2476690654]: Index(['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier',\n",
      "       'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type'],\n",
      "      dtype='object')\n",
      "[2022-09-24 16:54:33,322: INFO: 2476690654]: Index(['Item_Identifier', 'Item_Fat_Content', 'Item_Type', 'Outlet_Identifier',\n",
      "       'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type'],\n",
      "      dtype='object')\n",
      "[2022-09-24 16:54:33,333: INFO: 2476690654]: Saving transformed training and testing array.\n",
      "[2022-09-24 16:54:33,345: INFO: common]: created directory at: artifacts\\preprocessed\n",
      "[2022-09-24 16:54:33,346: INFO: 2476690654]: Saving preprocessing object at artifacts\\preprocessed\\preprocessed.pkl type <class 'sklearn.compose._column_transformer.ColumnTransformer'>\n",
      "[2022-09-24 16:54:33,351: INFO: common]: binary file saved at: artifacts\\preprocessed\\preprocessed.pkl\n",
      "[2022-09-24 16:54:33,351: INFO: 2476690654]: Data transformationa completed successfully.\n"
     ]
    }
   ],
   "source": [
    "config = ConfigurationManager()\n",
    "config = config.get_data_transformation_config()\n",
    "trans = DataTransformation(config)\n",
    "trans.initiate_data_transformation()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Establishment_Year</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCM55</td>\n",
       "      <td>15.60</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.111686</td>\n",
       "      <td>Others</td>\n",
       "      <td>184.7924</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>370.1848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FDU01</td>\n",
       "      <td>20.25</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.012063</td>\n",
       "      <td>Canned</td>\n",
       "      <td>183.5924</td>\n",
       "      <td>OUT017</td>\n",
       "      <td>2007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2406.2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDJ22</td>\n",
       "      <td>18.75</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.053025</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>192.5504</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>2009</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>2109.2544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX31</td>\n",
       "      <td>20.35</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>234.4958</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>1402.1748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FDN21</td>\n",
       "      <td>18.60</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.076841</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>162.2236</td>\n",
       "      <td>OUT035</td>\n",
       "      <td>2004</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2900.2248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5705</th>\n",
       "      <td>NCN29</td>\n",
       "      <td>15.20</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.020280</td>\n",
       "      <td>Health and Hygiene</td>\n",
       "      <td>49.1034</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>1998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>194.4136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>FDP21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.025616</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>188.1872</td>\n",
       "      <td>OUT027</td>\n",
       "      <td>1985</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type3</td>\n",
       "      <td>6239.8776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5707</th>\n",
       "      <td>FDO22</td>\n",
       "      <td>13.50</td>\n",
       "      <td>Regular</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Snack Foods</td>\n",
       "      <td>78.3960</td>\n",
       "      <td>OUT035</td>\n",
       "      <td>2004</td>\n",
       "      <td>Small</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>1438.1280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5708</th>\n",
       "      <td>FDI52</td>\n",
       "      <td>18.70</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.104890</td>\n",
       "      <td>Frozen Foods</td>\n",
       "      <td>121.4072</td>\n",
       "      <td>OUT045</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tier 2</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3185.1872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5709</th>\n",
       "      <td>FDI35</td>\n",
       "      <td>14.00</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>0.041355</td>\n",
       "      <td>Starchy Foods</td>\n",
       "      <td>182.0634</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>1999</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>4544.0850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5710 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0              NCM55        15.60          Low Fat         0.111686   \n",
       "1              FDU01        20.25          Regular         0.012063   \n",
       "2              FDJ22        18.75          Low Fat         0.053025   \n",
       "3              FDX31        20.35          Regular         0.000000   \n",
       "4              FDN21        18.60          Low Fat         0.076841   \n",
       "...              ...          ...              ...              ...   \n",
       "5705           NCN29        15.20          Low Fat         0.020280   \n",
       "5706           FDP21          NaN          Regular         0.025616   \n",
       "5707           FDO22        13.50          Regular         0.000000   \n",
       "5708           FDI52        18.70          Low Fat         0.104890   \n",
       "5709           FDI35        14.00          Low Fat         0.041355   \n",
       "\n",
       "                  Item_Type  Item_MRP Outlet_Identifier  \\\n",
       "0                    Others  184.7924            OUT010   \n",
       "1                    Canned  183.5924            OUT017   \n",
       "2               Snack Foods  192.5504            OUT018   \n",
       "3     Fruits and Vegetables  234.4958            OUT045   \n",
       "4               Snack Foods  162.2236            OUT035   \n",
       "...                     ...       ...               ...   \n",
       "5705     Health and Hygiene   49.1034            OUT010   \n",
       "5706            Snack Foods  188.1872            OUT027   \n",
       "5707            Snack Foods   78.3960            OUT035   \n",
       "5708           Frozen Foods  121.4072            OUT045   \n",
       "5709          Starchy Foods  182.0634            OUT049   \n",
       "\n",
       "      Outlet_Establishment_Year Outlet_Size Outlet_Location_Type  \\\n",
       "0                          1998         NaN               Tier 3   \n",
       "1                          2007         NaN               Tier 2   \n",
       "2                          2009      Medium               Tier 3   \n",
       "3                          2002         NaN               Tier 2   \n",
       "4                          2004       Small               Tier 2   \n",
       "...                         ...         ...                  ...   \n",
       "5705                       1998         NaN               Tier 3   \n",
       "5706                       1985      Medium               Tier 3   \n",
       "5707                       2004       Small               Tier 2   \n",
       "5708                       2002         NaN               Tier 2   \n",
       "5709                       1999      Medium               Tier 1   \n",
       "\n",
       "            Outlet_Type  Item_Outlet_Sales  \n",
       "0         Grocery Store           370.1848  \n",
       "1     Supermarket Type1          2406.2012  \n",
       "2     Supermarket Type2          2109.2544  \n",
       "3     Supermarket Type1          1402.1748  \n",
       "4     Supermarket Type1          2900.2248  \n",
       "...                 ...                ...  \n",
       "5705      Grocery Store           194.4136  \n",
       "5706  Supermarket Type3          6239.8776  \n",
       "5707  Supermarket Type1          1438.1280  \n",
       "5708  Supermarket Type1          3185.1872  \n",
       "5709  Supermarket Type1          4544.0850  \n",
       "\n",
       "[5710 rows x 12 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"artifacts\\data_ingestion\\ingested_train_dir\\Train.csv\",index_col=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9cbb0b948f33c3107f482a8001e5ae7cac736ef069ea6ca766c7281b6fed019f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
